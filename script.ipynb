{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5a683f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "profile = ProfileReport(df, title=\"My Data Report\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4471efb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3934c438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in dataframe:\n",
      "['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'num       ']\n",
      "\n",
      "Shape: (293, 14)\n",
      "\n",
      "First few rows:\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns in dataframe:\")\n",
    "print(df.columns.tolist())\n",
    "print(f\"\\nShape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72981ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "oldpeak\n",
       "0.0    188\n",
       "1.0     41\n",
       "2.0     31\n",
       "1.5     16\n",
       "3.0      9\n",
       "2.5      3\n",
       "0.5      2\n",
       "0.8      1\n",
       "4.0      1\n",
       "5.0      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Replace '?' with NaN across entire dataframe\n",
    "df = df.replace('?', 0)\n",
    "\n",
    "# Convert numeric columns to proper numeric type\n",
    "numeric_cols = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', \n",
    "                'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']\n",
    "\n",
    "for col in numeric_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Fill missing values with median or 0\n",
    "df = df.fillna(0)\n",
    "\n",
    "target_name = \"num\"\n",
    "\n",
    "x = df.drop(columns=\"num\")\n",
    "y = df[target_name]\n",
    "x.head()\n",
    "df[\"oldpeak\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6104d646",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47696fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.6610169491525424\n",
      "\n",
      " F1:\n",
      " 0.4117647058823529\n",
      "\n",
      " Precision score is:\n",
      " 0.4375\n",
      "\n",
      " Recall score is:\n",
      " 0.3888888888888889\n",
      "confusion matrix is:\n",
      " [[32  9]\n",
      " [11  7]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import  f1_score, precision_score, recall_score, accuracy_score, confusion_matrix\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred = knn.predict(x_test)\n",
    "print(\"accuracy_score:\",accuracy_score(y_test,y_pred))\n",
    "print(\"\\n F1:\\n\",f1_score(y_test,y_pred))\n",
    "print(\"\\n Precision score is:\\n\",precision_score(y_test,y_pred))\n",
    "print(\"\\n Recall score is:\\n\",recall_score(y_test,y_pred))\n",
    "print( \"confusion matrix is:\\n\",confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d547bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "accuracy_score: 0.7966101694915254\n",
      "\n",
      "F1: 0.7272727272727273\n",
      "\n",
      "Precision score: 0.6153846153846154\n",
      "\n",
      "Recall score: 0.8888888888888888\n",
      "confusion matrix is:\n",
      " [[31 10]\n",
      " [ 2 16]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the model\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'max_iter': [100, 200, 300],\n",
    "\n",
    "}\n",
    "\n",
    "# Apply GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=lr,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,                # 5-fold cross-validation\n",
    "    scoring='accuracy',  # You can also use 'f1', 'precision', 'recall'\n",
    "    n_jobs=-1            # Use all cores for faster computation\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Best estimator\n",
    "best_lr = grid_search.best_estimator_\n",
    "\n",
    "# Predictions with best model\n",
    "lr_pred = best_lr.predict(x_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"accuracy_score:\", accuracy_score(y_test, lr_pred))\n",
    "print(\"\\nF1:\", f1_score(y_test, lr_pred))\n",
    "print(\"\\nPrecision score:\", precision_score(y_test, lr_pred))\n",
    "print(\"\\nRecall score:\", recall_score(y_test, lr_pred))\n",
    "print( \"confusion matrix is:\\n\",confusion_matrix(y_test,lr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc89e3e8",
   "metadata": {},
   "source": [
    "## We observe :\n",
    "### The accuracy of the modal is 72% \n",
    "### The confusion matrix mostly predict correctly\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
